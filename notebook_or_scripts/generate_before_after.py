#!/usr/bin/env python3
"""
Generate Before/After Images for Arcade AI Challenge
Creates all 16 required images (8 prompts √ó baseline + optimized)
"""

import torch
import os
from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler
import time
from datetime import datetime

# The 8 required prompts (verbatim from challenge)
REQUIRED_PROMPTS = [
    "channel-set diamond eternity band, 2 mm width, hammered 18k yellow gold, product-only white background",
    "14k rose-gold threader earrings, bezel-set round lab diamond ends, lifestyle macro shot, soft natural light",
    "organic cluster ring with mixed-cut sapphires and diamonds, brushed platinum finish, modern aesthetic",
    "A solid gold cuff bracelet with blue sapphire, with refined simplicity and intentionally crafted for everyday wear",
    "modern signet ring, oval face, engraved gothic initial 'M', high-polish sterling silver, subtle reflection",
    "delicate gold huggie hoops, contemporary styling, isolated on neutral background",
    "stack of three slim rings: twisted gold, plain platinum, black rhodium pav√©, editorial lighting",
    "bypass ring with stones on it, with refined simplicity and intentionally crafted for everyday wear"
]

# LoRA adapter paths and configuration
LORA_ADAPTERS = {
    "channel_set": "lora_adapters/channel-set/checkpoint/pytorch_lora_weights.safetensors",
    "threader": "lora_adapters/threader/checkpoint/pytorch_lora_weights.safetensors", 
    "huggie": "lora_adapters/huggie/checkpoint/pytorch_lora_weights.safetensors"
}

# Special tokens for enhanced grounding
SPECIAL_TOKENS = {
    "channel_set": "sks",
    "threader": "phol"
}

def detect_jewelry_category(prompt):
    """Detect jewelry category for LoRA selection"""
    prompt_lower = prompt.lower()
    
    if "channel-set" in prompt_lower:
        return "channel_set"
    elif "threader" in prompt_lower:
        return "threader" 
    elif "huggie" in prompt_lower:
        return "huggie"
    else:
        return None

def load_lora_adapter(pipeline, category):
    """Load appropriate LoRA adapter for the jewelry category"""
    if category and category in LORA_ADAPTERS:
        lora_path = LORA_ADAPTERS[category]
        if os.path.exists(lora_path):
            print(f"üîß Loading {category} LoRA adapter...")
            pipeline.load_lora_weights(lora_path)
            return True
        else:
            print(f"‚ö†Ô∏è  LoRA adapter not found: {lora_path}")
            return False
    return False

def unload_lora_adapter(pipeline):
    """Unload current LoRA adapter"""
    try:
        pipeline.unload_lora_weights()
    except:
        # No LoRA to unload or not supported
        pass

def setup_pipeline(device="cuda"):
    """Setup SD 1.5 pipeline with optimal configuration"""
    print("üîß Loading SD 1.5 pipeline...")
    
    # Use FP16 on GPU for speed
    dtype = torch.float16 if device == "cuda" else torch.float32
    variant = "fp16" if device == "cuda" else None
    
    pipeline = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=dtype,
        variant=variant
    )
    
    # Set optimal sampler (Euler Ancestral from human evaluation)
    pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(
        pipeline.scheduler.config
    )
    
    pipeline.to(device)
    
    # Memory optimizations
    if device == "cuda":
        pipeline.enable_memory_efficient_attention()
    else:
        pipeline.enable_attention_slicing()
    
    print(f"‚úÖ Pipeline ready on {device}")
    return pipeline

def apply_jewelry_enhancement(prompt, category=None):
    """Apply custom attention weighting using native diffusers syntax"""
    
    enhanced_prompt = prompt
    
    # Add special tokens for trained categories first
    if category and category in SPECIAL_TOKENS:
        special_token = SPECIAL_TOKENS[category]
        if category == "channel_set" and "channel-set" in enhanced_prompt:
            enhanced_prompt = enhanced_prompt.replace("channel-set", f"{special_token} channel-set")
        elif category == "threader" and "threader" in enhanced_prompt:
            enhanced_prompt = enhanced_prompt.replace("threader", f"{special_token} threader")
    
    # Apply prompt-specific attention weighting using diffusers syntax
    if "channel-set diamond eternity band" in prompt:
        # Prompt 1: channel-set
        enhanced_prompt = enhanced_prompt.replace("sks channel-set", "(sks channel-set:1.2)")
        enhanced_prompt = enhanced_prompt.replace("diamond", "(diamond:1.2)")
        enhanced_prompt = enhanced_prompt.replace("hammered", "(hammered:1.2)")
        enhanced_prompt = enhanced_prompt.replace("gold", "(gold:1.2)")
        enhanced_prompt = enhanced_prompt.replace("product-only", "(product-only:1.2)")
        enhanced_prompt = enhanced_prompt.replace("white background", "(white background:1.2)")
        
    elif "14k rose-gold threader earrings" in prompt:
        # Prompt 2: threader
        enhanced_prompt = enhanced_prompt.replace("rose-gold", "(rose-gold:1.2)")
        enhanced_prompt = enhanced_prompt.replace("phol threader", "(phol threader:1.2)")
        enhanced_prompt = enhanced_prompt.replace("bezel-set", "(bezel-set:1.2)")
        enhanced_prompt = enhanced_prompt.replace("diamond", "(diamond:1.2)")
        enhanced_prompt = enhanced_prompt.replace("lifestyle", "(lifestyle:1.2)")
        enhanced_prompt = enhanced_prompt.replace("macro", "(macro:1.2)")
        
    elif "organic cluster ring with mixed-cut sapphires" in prompt:
        # Prompt 3: organic cluster
        enhanced_prompt = enhanced_prompt.replace("organic cluster", "(organic cluster:1.2)")
        enhanced_prompt = enhanced_prompt.replace("sapphires", "(sapphires:1.2)")
        enhanced_prompt = enhanced_prompt.replace("diamonds", "(diamonds:1.2)")
        enhanced_prompt = enhanced_prompt.replace("brushed", "(brushed:1.2)")
        enhanced_prompt = enhanced_prompt.replace("platinum", "(platinum:1.2)")
        enhanced_prompt = enhanced_prompt.replace("modern", "(modern:1.2)")
        
    elif "solid gold cuff bracelet with blue sapphire" in prompt:
        # Prompt 4: cuff bracelet
        enhanced_prompt = enhanced_prompt.replace("gold", "(gold:1.2)")
        enhanced_prompt = enhanced_prompt.replace("cuff bracelet", "(cuff bracelet:1.2)")
        enhanced_prompt = enhanced_prompt.replace("blue sapphire", "(blue sapphire:1.2)")
        enhanced_prompt = enhanced_prompt.replace("refined", "(refined:1.2)")
        
    elif "modern signet ring, oval face, engraved gothic" in prompt:
        # Prompt 5: signet ring
        enhanced_prompt = enhanced_prompt.replace("modern", "(modern:1.2)")
        enhanced_prompt = enhanced_prompt.replace("signet", "(signet:1.2)")
        enhanced_prompt = enhanced_prompt.replace("engraved gothic initial 'M'", "(engraved gothic initial 'M':1.2)")
        enhanced_prompt = enhanced_prompt.replace("sterling", "(sterling:1.2)")
        enhanced_prompt = enhanced_prompt.replace("silver", "(silver:1.2)")
        
    elif "delicate gold huggie hoops" in prompt:
        # Prompt 6: huggie hoops
        enhanced_prompt = enhanced_prompt.replace("delicate", "(delicate:1.2)")
        enhanced_prompt = enhanced_prompt.replace("gold", "(gold:1.2)")
        enhanced_prompt = enhanced_prompt.replace("huggie hoops", "(huggie hoops:1.2)")
        enhanced_prompt = enhanced_prompt.replace("contemporary", "(contemporary:1.2)")
        
    elif "stack of three slim rings" in prompt:
        # Prompt 7: ring stack
        enhanced_prompt = enhanced_prompt.replace("stack of three", "(stack of three:1.2)")
        enhanced_prompt = enhanced_prompt.replace("gold", "(gold:1.2)")
        enhanced_prompt = enhanced_prompt.replace("platinum", "(platinum:1.2)")
        enhanced_prompt = enhanced_prompt.replace("pav√©", "(pav√©:1.2)")
        enhanced_prompt = enhanced_prompt.replace("editorial", "(editorial:1.2)")
        
    elif "bypass ring with stones" in prompt:
        # Prompt 8: bypass ring
        enhanced_prompt = enhanced_prompt.replace("bypass ring", "(bypass ring:1.2)")
        enhanced_prompt = enhanced_prompt.replace("refined", "(refined:1.2)")
    
    return enhanced_prompt

def generate_baseline_image(pipeline, prompt, seed=42):
    """Generate baseline image with default settings"""
    
    generator = torch.Generator(device=pipeline.device).manual_seed(seed)
    
    image = pipeline(
        prompt=prompt,
        num_inference_steps=20,
        guidance_scale=7.5,  # Default CFG
        generator=generator,
        height=512,
        width=512
    ).images[0]
    
    return image

def generate_optimized_image(pipeline, prompt, seed=42):
    """Generate optimized image with research-backed settings and LoRA"""
    
    # Detect jewelry category for LoRA selection
    category = detect_jewelry_category(prompt)
    
    # Load appropriate LoRA adapter
    lora_loaded = False
    if category:
        lora_loaded = load_lora_adapter(pipeline, category)
    
    # Apply prompt enhancement with special tokens and attention weighting
    enhanced_prompt = apply_jewelry_enhancement(prompt, category)
    
    generator = torch.Generator(device=pipeline.device).manual_seed(seed)
    
    image = pipeline(
        prompt=enhanced_prompt,      # Use enhanced prompt with native diffusers syntax
        num_inference_steps=20,      # Optimal from research
        guidance_scale=9.0,          # Optimal CFG from human evaluation
        generator=generator,
        height=512,
        width=512
    ).images[0]
    
    # Unload LoRA adapter for next generation
    if lora_loaded:
        unload_lora_adapter(pipeline)
    
    return image, enhanced_prompt, category

def generate_all_comparisons():
    """Generate all 16 required images"""
    
    # Setup
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üöÄ Starting generation on {device}")
    print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    pipeline = setup_pipeline(device)
    
    # Create output directory
    output_dir = "deliverables/before_after"
    os.makedirs(output_dir, exist_ok=True)
    
    total_start = time.time()
    results = []
    
    for i, prompt in enumerate(REQUIRED_PROMPTS, 1):
        print(f"--- Prompt {i:02d}/08 ---")
        print(f"'{prompt[:60]}...'")
        
        # Generate baseline
        print("üî∏ Generating baseline...")
        start_time = time.time()
        baseline_image = generate_baseline_image(pipeline, prompt, seed=42)
        baseline_time = time.time() - start_time
        
        # Save baseline
        baseline_path = f"{output_dir}/prompt{i:02d}_baseline.png"
        baseline_image.save(baseline_path)
        
        # Generate optimized
        print("üîπ Generating optimized...")
        start_time = time.time()
        optimized_image, enhanced_prompt, category = generate_optimized_image(
            pipeline, prompt, seed=42
        )
        optimized_time = time.time() - start_time
        
        # Save optimized
        optimized_path = f"{output_dir}/prompt{i:02d}_yours.png"
        optimized_image.save(optimized_path)
        
        results.append({
            'prompt_num': i,
            'original_prompt': prompt,
            'enhanced_prompt': enhanced_prompt,
            'category': category,
            'lora_used': category is not None,
            'baseline_time': baseline_time,
            'optimized_time': optimized_time,
            'baseline_path': baseline_path,
            'optimized_path': optimized_path
        })
        
        print(f"‚úÖ Saved: {baseline_path}")
        print(f"‚úÖ Saved: {optimized_path}")
        print(f"‚è±Ô∏è  Times: baseline {baseline_time:.1f}s, optimized {optimized_time:.1f}s\n")
    
    total_time = time.time() - total_start
    
    # Summary
    print("üéØ GENERATION COMPLETE!")
    print("="*60)
    print(f"üìÅ Output directory: {output_dir}")
    print(f"üì∏ Images generated: {len(results) * 2}")
    print(f"‚è±Ô∏è  Total time: {total_time:.1f}s")
    print(f"‚ö° Average per image: {total_time/(len(results)*2):.1f}s")
    
    avg_baseline = sum(r['baseline_time'] for r in results) / len(results)
    avg_optimized = sum(r['optimized_time'] for r in results) / len(results)
    print(f"üìä Baseline avg: {avg_baseline:.1f}s, Optimized avg: {avg_optimized:.1f}s")
    
    # File verification
    print(f"\nüìã Generated Files:")
    for i in range(1, 9):
        baseline_file = f"prompt{i:02d}_baseline.png"
        optimized_file = f"prompt{i:02d}_yours.png"
        print(f"  {baseline_file} ‚úÖ")
        print(f"  {optimized_file} ‚úÖ")
    
    # LoRA usage summary
    lora_usage = {}
    for result in results:
        if result['lora_used']:
            category = result['category']
            lora_usage[category] = lora_usage.get(category, 0) + 1
    
    print(f"\nüé® Key Improvements Applied:")
    print(f"  ‚Ä¢ Native diffusers attention weighting on jewelry terms")
    print(f"  ‚Ä¢ Special tokens: 'sks' for channel-set, 'phol' for threader")
    print(f"  ‚Ä¢ Optimal CFG scale: 9.0 (vs 7.5 baseline)")
    print(f"  ‚Ä¢ Euler Ancestral sampler for quality")
    print(f"  ‚Ä¢ Consistent seed (42) for reproducibility")
    
    if lora_usage:
        print(f"\nüß† LoRA Adapters Used:")
        for category, count in lora_usage.items():
            print(f"  ‚Ä¢ {category}: {count} prompt(s)")
    else:
        print(f"\n‚ö†Ô∏è  No LoRA adapters found - using base model only")
    
    return results

def preview_all_optimized_prompts():
    """Preview all optimized prompts without generating images"""
    
    print("\nüîç OPTIMIZED PROMPT PREVIEW")
    print("="*80)
    print("Showing all 8 prompts with optimization transformations")
    print("="*80)
    
    for i, prompt in enumerate(REQUIRED_PROMPTS, 1):
        category = detect_jewelry_category(prompt)
        enhanced = apply_jewelry_enhancement(prompt, category)
        
        # Status indicators
        lora_status = f"‚úÖ LoRA: {category}" if category else "‚ùå No LoRA"
        special_token = f"üè∑Ô∏è  Token: {SPECIAL_TOKENS.get(category, 'None')}" if category else "üè∑Ô∏è  Token: None"
        
        print(f"\n{'='*15} PROMPT {i:02d}/08 {'='*15}")
        print(f"Category: {lora_status}")
        print(f"Special Token: {special_token}")
        print(f"\nüìù ORIGINAL:")
        print(f"   {prompt}")
        print(f"\nüöÄ OPTIMIZED:")
        print(f"   {enhanced}")
        
        # Show key transformations
        changes = []
        if category and category in SPECIAL_TOKENS:
            if category == "channel_set" and "sks channel-set" in enhanced:
                changes.append("Added 'sks' token before 'channel-set'")
            elif category == "threader" and "phol threader" in enhanced:
                changes.append("Added 'phol' token before 'threader'")
        
        # Count emphasis weights
        emphasis_count = enhanced.count(")1.2")
        if emphasis_count > 0:
            changes.append(f"Applied 1.2x emphasis to {emphasis_count} jewelry terms")
        
        if changes:
            print(f"\nüîß TRANSFORMATIONS:")
            for change in changes:
                print(f"   ‚Ä¢ {change}")
    
    print(f"\n{'='*80}")
    print(f"üìä SUMMARY:")
    
    # Count categories
    categories = {}
    for prompt in REQUIRED_PROMPTS:
        cat = detect_jewelry_category(prompt)
        if cat:
            categories[cat] = categories.get(cat, 0) + 1
    
    print(f"   ‚Ä¢ Total prompts: {len(REQUIRED_PROMPTS)}")
    print(f"   ‚Ä¢ LoRA-enhanced: {sum(categories.values())}")
    print(f"   ‚Ä¢ Base model only: {len(REQUIRED_PROMPTS) - sum(categories.values())}")
    
    if categories:
        print(f"   ‚Ä¢ LoRA breakdown:")
        for cat, count in categories.items():
            print(f"     - {cat}: {count} prompt(s)")
    
    print(f"{'='*80}")

def show_enhancement_examples():
    """Show examples of prompt enhancements"""
    
    print("\nüí° Example Prompt Enhancements:")
    print("="*60)
    
    example_prompts = REQUIRED_PROMPTS[:3]
    
    for i, prompt in enumerate(example_prompts, 1):
        category = detect_jewelry_category(prompt)
        enhanced = apply_jewelry_enhancement(prompt, category)
        lora_info = f" ‚Üí LoRA: {category}" if category else " ‚Üí No LoRA"
        
        print(f"\nPrompt {i}{lora_info}:")
        print(f"Original : {prompt}")
        print(f"Enhanced : {enhanced}")
    
    print("="*60)

if __name__ == "__main__":
    import sys
    
    # Check for preview-only mode
    if len(sys.argv) > 1 and sys.argv[1] == "--preview":
        print("üîç PROMPT PREVIEW MODE")
        print("="*60)
        preview_all_optimized_prompts()
        print("\n‚úÖ Preview complete! Remove --preview flag to generate images.")
        sys.exit(0)
    
    print("üé® Arcade AI Challenge - Before/After Generation")
    print("="*60)
    print("Generating 16 images (8 prompts √ó baseline + optimized)")
    print("Using optimal configuration from human evaluation research")
    
    show_enhancement_examples()
    
    # Generate all images
    results = generate_all_comparisons()
    
    print(f"\n‚úÖ All deliverable images ready!")
    print(f"üìÅ Check: deliverables/before_after/")
    print(f"üéØ Ready for submission!")
