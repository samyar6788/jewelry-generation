{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Before/After Images for Arcade AI Challenge\n",
        "\n",
        "Creates all 16 required images (8 prompts √ó baseline + optimized)\n",
        "\n",
        "This notebook implements the complete optimization strategy:\n",
        "- **LoRA adapters** for specific jewelry categories\n",
        "- **Special tokens** (sks, phol) for enhanced grounding\n",
        "- **Native diffusers attention weighting** for jewelry terms\n",
        "- **Optimal parameters** from human evaluation research\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image as IPImage\n",
        "from PIL import Image\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The 8 required prompts (verbatim from challenge)\n",
        "REQUIRED_PROMPTS = [\n",
        "    \"channel-set diamond eternity band, 2 mm width, hammered 18k yellow gold, product-only white background\",\n",
        "    \"14k rose-gold threader earrings, bezel-set round lab diamond ends, lifestyle macro shot, soft natural light\",\n",
        "    \"organic cluster ring with mixed-cut sapphires and diamonds, brushed platinum finish, modern aesthetic\",\n",
        "    \"A solid gold cuff bracelet with blue sapphire, with refined simplicity and intentionally crafted for everyday wear\",\n",
        "    \"modern signet ring, oval face, engraved gothic initial 'M', high-polish sterling silver, subtle reflection\",\n",
        "    \"delicate gold huggie hoops, contemporary styling, isolated on neutral background\",\n",
        "    \"stack of three slim rings: twisted gold, plain platinum, black rhodium pav√©, editorial lighting\",\n",
        "    \"bypass ring with stones on it, with refined simplicity and intentionally crafted for everyday wear\"\n",
        "]\n",
        "\n",
        "# LoRA adapter paths and configuration\n",
        "LORA_ADAPTERS = {\n",
        "    \"channel_set\": \"../lora_adapters/channel-set/checkpoint/pytorch_lora_weights.safetensors\",\n",
        "    \"threader\": \"../lora_adapters/threader/checkpoint/pytorch_lora_weights.safetensors\", \n",
        "    \"huggie\": \"../lora_adapters/huggie/checkpoint/pytorch_lora_weights.safetensors\"\n",
        "}\n",
        "\n",
        "# Special tokens for enhanced grounding\n",
        "SPECIAL_TOKENS = {\n",
        "    \"channel_set\": \"sks\",\n",
        "    \"threader\": \"phol\"\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Configuration loaded: {len(REQUIRED_PROMPTS)} prompts, {len(LORA_ADAPTERS)} LoRA adapters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n",
        "\n",
        "Copy the helper functions from the Python script:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy all functions from generate_before_after.py\n",
        "exec(open('../notebook_or_scripts/generate_before_after.py').read().split('if __name__ == \"__main__\":')[0])\n",
        "\n",
        "print(\"‚úÖ All functions loaded from generate_before_after.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup pipeline\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipeline = setup_pipeline(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preview Prompts\n",
        "\n",
        "First, let's see what the optimized prompts look like:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview all optimized prompts\n",
        "for i, prompt in enumerate(REQUIRED_PROMPTS[:3], 1):  # Show first 3 for preview\n",
        "    category = detect_jewelry_category(prompt)\n",
        "    enhanced = apply_jewelry_enhancement(prompt, category)\n",
        "    \n",
        "    print(f\"=== PROMPT {i:02d} ===\")\n",
        "    print(f\"Category: {'‚úÖ LoRA: ' + category if category else '‚ùå No LoRA'}\")\n",
        "    print(f\"Original: {prompt}\")\n",
        "    print(f\"Enhanced: {enhanced}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Single Image\n",
        "\n",
        "Let's test with one prompt to make sure everything works:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with the first prompt\n",
        "test_prompt = REQUIRED_PROMPTS[0]\n",
        "print(f\"Testing with: {test_prompt}\")\n",
        "\n",
        "# Generate baseline and optimized\n",
        "print(\"\\nüî∏ Generating baseline...\")\n",
        "baseline_image = generate_baseline_image(pipeline, test_prompt, seed=42)\n",
        "\n",
        "print(\"üîπ Generating optimized...\")\n",
        "optimized_image, enhanced_prompt, category = generate_optimized_image(pipeline, test_prompt, seed=42)\n",
        "\n",
        "print(f\"\\n‚úÖ Test complete!\")\n",
        "print(f\"Enhanced prompt: {enhanced_prompt}\")\n",
        "print(f\"Category: {category}\")\n",
        "\n",
        "# Display images side by side\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "ax1.imshow(baseline_image)\n",
        "ax1.set_title(\"Baseline (CFG=7.5)\")\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(optimized_image)\n",
        "ax2.set_title(f\"Optimized (CFG=9.0, LoRA={category})\")\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate All 16 Images\n",
        "\n",
        "‚ö†Ô∏è **Warning**: This will take a while to complete (especially on CPU). Each image takes ~1-3 minutes to generate.\n",
        "\n",
        "Run the complete generation using the function from the script:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate all 16 images (8 baseline + 8 optimized)\n",
        "# This uses the generate_all_comparisons() function from the script\n",
        "\n",
        "results = generate_all_comparisons()\n",
        "\n",
        "print(\"\\nüéØ GENERATION COMPLETE!\")\n",
        "print(\"‚úÖ All 16 deliverable images ready!\")\n",
        "print(\"üìÅ Check: deliverables/before_after/\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
